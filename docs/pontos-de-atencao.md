# Pontos de Aten√ß√£o - Integration Hub

## 1. Riscos T√©cnicos e Mitiga√ß√µes

### 1.1. Lat√™ncia de Sistemas Externos

**Risco:**
Sistemas externos podem responder lentamente (> 5s) ou n√£o responder, bloqueando o processamento de requisi√ß√µes.

**Impacto:**
- ‚ö†Ô∏è Ac√∫mulo de mensagens na fila
- ‚ö†Ô∏è Timeout de requisi√ß√µes
- ‚ö†Ô∏è Degrada√ß√£o da experi√™ncia do usu√°rio

**Mitiga√ß√£o:**

1. **Timeout Configur√°vel:**
   ```csharp
   var httpClient = new HttpClient
   {
       Timeout = TimeSpan.FromSeconds(60) // Timeout agressivo
   };
   ```

2. **Circuit Breaker (Polly):**
   ```csharp
   var circuitBreakerPolicy = Policy
       .Handle<HttpRequestException>()
       .CircuitBreakerAsync(
           handledEventsAllowedBeforeBreaking: 5, // Abre circuito ap√≥s 5 falhas
           durationOfBreak: TimeSpan.FromMinutes(1) // Mant√©m aberto por 1 minuto
       );
   ```

3. **Fallback para Modo Degradado:**
   - Se sistema externo indispon√≠vel > 10 minutos, aciona alertas
   - Requisi√ß√µes s√£o marcadas como `WaitingExternal` e reprocessadas quando servi√ßo volta

4. **SLA com Fornecedores:**
   - Definir SLA de lat√™ncia (p95 < 2s)
   - Monitorar via m√©tricas: `external_system_call_duration_seconds`

**Monitoramento:**
```promql
# Alerta se p95 > 5s
histogram_quantile(0.95, rate(external_system_call_duration_seconds_bucket[5m])) > 5
```

---

### 1.2. Versionamento de Contratos

**Risco:**
Mudan√ßas em schemas de payload (breaking changes) quebram integra√ß√µes existentes.

**Impacto:**
- ‚ùå Parceiros n√£o conseguem enviar requisi√ß√µes
- ‚ùå Valida√ß√µes falham inesperadamente
- ‚ùå Dados corrompidos

**Mitiga√ß√£o:**

1. **Versionamento de API:**
   ```csharp
   [ApiVersion("1.0")]
   [ApiVersion("2.0")]
   [Route("api/v{version:apiVersion}/integration-requests")]
   public class IntegrationRequestsController : ControllerBase
   {
       [HttpPost]
       [MapToApiVersion("1.0")]
       public async Task<IActionResult> CreateV1([FromBody] CreateIntegrationRequestCommandV1 command)
       {
           // Implementa√ß√£o V1
       }

       [HttpPost]
       [MapToApiVersion("2.0")]
       public async Task<IActionResult> CreateV2([FromBody] CreateIntegrationRequestCommandV2 command)
       {
           // Implementa√ß√£o V2 com novos campos
       }
   }
   ```

2. **Backward Compatibility:**
   - Novos campos devem ser **opcionais** (nullable)
   - Nunca remover campos existentes
   - Deprecate antes de remover:
     ```csharp
     [Obsolete("Use 'NewFieldName' instead. Will be removed in v3.0")]
     public string OldFieldName { get; set; }
     ```

3. **Schema Validation com JSON Schema:**
   ```csharp
   public class PayloadValidator
   {
       public bool Validate(string payload, string schemaVersion)
       {
           var schema = GetSchema(schemaVersion); // Busca schema da vers√£o
           var jsonSchema = JsonSchema.FromText(schema);
           var errors = jsonSchema.Validate(payload);
           return !errors.Any();
       }
   }
   ```

4. **Comunica√ß√£o Proativa:**
   - Notificar parceiros com **90 dias de anteced√™ncia** de breaking changes
   - Manter vers√µes antigas por **m√≠nimo 6 meses** ap√≥s depreca√ß√£o
   - Documentar changelogs: `/docs/api-changelog.md`

**Monitoramento:**
```promql
# Alerta se uso de vers√£o antiga > 10% ap√≥s per√≠odo de depreca√ß√£o
sum(rate(http_requests_total{api_version="1.0"}[5m])) / sum(rate(http_requests_total[5m])) > 0.1
```

---

### 1.3. Falhas Intermitentes

**Risco:**
Falhas transientes em rede, banco de dados ou sistemas externos causam erros espor√°dicos.

**Impacto:**
- ‚ö†Ô∏è Requisi√ß√µes marcadas como `Failed` indevidamente
- ‚ö†Ô∏è Experi√™ncia inconsistente para parceiros
- ‚ö†Ô∏è Aumento de tickets de suporte

**Mitiga√ß√£o:**

1. **Retry com Exponential Backoff (Polly):**
   ```csharp
   var retryPolicy = Policy
       .Handle<HttpRequestException>()
       .Or<TimeoutException>()
       .WaitAndRetryAsync(
           retryCount: 3,
           sleepDurationProvider: retryAttempt => 
               TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)), // 2s, 4s, 8s
           onRetry: (exception, timeSpan, retryCount, context) =>
           {
               _logger.LogWarning(
                   "Retry {RetryCount} after {Duration}ms due to {Exception}",
                   retryCount, timeSpan.TotalMilliseconds, exception.GetType().Name
               );
           }
       );
   ```

2. **Jitter para Evitar Thundering Herd:**
   ```csharp
   var jitter = TimeSpan.FromMilliseconds(Random.Shared.Next(0, 1000));
   var delay = baseDelay + jitter;
   await Task.Delay(delay);
   ```

3. **Idempot√™ncia:**
   - Toda opera√ß√£o deve ser **idempotente**
   - Se retry da mesma requisi√ß√£o, resultado deve ser id√™ntico
   - `ExternalId` como chave de idempot√™ncia:
     ```csharp
     // Se j√° existe, retorna 409 Conflict com link para recurso existente
     var existing = await _repository.GetByExternalIdAsync(command.ExternalId);
     if (existing != null)
     {
         return Conflict(new 
         { 
             message = "Request already exists",
             location = $"/api/integration-requests/{existing.Id}"
         });
     }
     ```

4. **Health Checks de Depend√™ncias:**
   ```csharp
   builder.Services.AddHealthChecks()
       .AddSqlServer(connectionString, name: "database")
       .AddRabbitMQ(rabbitConnectionString, name: "messagebus")
       .AddUrlGroup(new Uri("https://api.totvs.com.br/health"), name: "external_system");
   ```

**Monitoramento:**
```promql
# Alerta se taxa de retry > 10%
rate(http_client_retries_total[5m]) / rate(http_client_requests_total[5m]) > 0.1
```

---

### 1.4. Reprocessamento e Dead-Letter Queue (DLQ)

**Risco:**
Mensagens falhadas ficam presas na fila principal, bloqueando consumo de novas mensagens.

**Impacto:**
- ‚ùå Fila principal congestionada
- ‚ùå Mensagens v√°lidas n√£o s√£o processadas
- ‚ùå SLA de lat√™ncia violado

**Mitiga√ß√£o:**

1. **Dead-Letter Queue (DLQ):**
   ```csharp
   // RabbitMQ: Configurar DLX (Dead Letter Exchange)
   channel.ExchangeDeclare(
       exchange: "integration.events.dlq",
       type: ExchangeType.Fanout,
       durable: true
   );

   var queueArgs = new Dictionary<string, object>
   {
       { "x-dead-letter-exchange", "integration.events.dlq" },
       { "x-message-ttl", 86400000 }, // 24 horas
       { "x-max-retries", 3 }
   };

   channel.QueueDeclare(
       queue: "integration-orchestration-queue",
       durable: true,
       arguments: queueArgs
   );
   ```

2. **Worker de DLQ (An√°lise Manual):**
   ```csharp
   // Job separado que processa DLQ overnight ou sob demanda
   public class DlqProcessorWorker : BackgroundService
   {
       protected override async Task ExecuteAsync(CancellationToken stoppingToken)
       {
           await foreach (var message in _dlqChannel.ReadAllAsync(stoppingToken))
           {
               _logger.LogWarning("DLQ message | Id={Id} | Error={Error}", 
                   message.RequestId, message.ErrorMessage);
               
               // Notificar equipe de opera√ß√µes
               await _alertService.SendAlert($"DLQ message requires manual review: {message.RequestId}");
           }
       }
   }
   ```

3. **Reprocessamento Manual:**
   ```csharp
   [HttpPost("admin/retry/{id}")]
   [Authorize(Roles = "Admin")]
   public async Task<IActionResult> RetryFailedRequest(Guid id)
   {
       var request = await _repository.GetByIdAsync(id);
       if (request.Status != IntegrationStatus.Failed)
       {
           return BadRequest("Only failed requests can be retried");
       }

       // Reset status e republica evento
       await _service.UpdateStatusAsync(id, IntegrationStatus.Received);
       await _messageBus.PublishAsync(new IntegrationRequestCreated
       {
           RequestId = id,
           CorrelationId = request.CorrelationId,
           ExternalId = request.ExternalId
       });

       return Ok();
   }
   ```

**Monitoramento:**
```promql
# Alerta se DLQ > 100 mensagens
messagebus_dlq_depth > 100
```

---

### 1.5. Monitoramento de Fila

**Risco:**
Fila cresce descontroladamente devido a processamento lento ou falhas no worker.

**Impacto:**
- ‚ö†Ô∏è Lat√™ncia aumenta drasticamente
- ‚ö†Ô∏è Out of Memory (OOM) no RabbitMQ
- ‚ö†Ô∏è SLA violado

**Mitiga√ß√£o:**

1. **M√©tricas de Fila:**
   ```csharp
   // Expor m√©trica Prometheus
   private static readonly Gauge QueueDepth = Metrics
       .CreateGauge("messagebus_queue_depth", "Depth of message queue");

   public async Task<int> GetQueueDepthAsync()
   {
       var management = new ManagementClient("http://rabbitmq:15672", "guest", "guest");
       var queue = await management.GetQueueAsync("integration-orchestration-queue");
       QueueDepth.Set(queue.MessagesReady);
       return queue.MessagesReady;
   }
   ```

2. **Auto-Scaling de Workers (KEDA):**
   ```yaml
   apiVersion: keda.sh/v1alpha1
   kind: ScaledObject
   metadata:
     name: integration-worker-scaler
   spec:
     scaleTargetRef:
       name: integration-worker
     minReplicaCount: 2
     maxReplicaCount: 10
     triggers:
       - type: rabbitmq
         metadata:
           queueName: integration-orchestration-queue
           queueLength: "50" # Escala se fila > 50 mensagens
   ```

3. **Alertas de Fila:**
   ```promql
   # Alerta se fila > 500 mensagens por 5 minutos
   messagebus_queue_depth > 500
   ```

4. **Backpressure:**
   ```csharp
   // Limitar concorr√™ncia do worker
   var semaphore = new SemaphoreSlim(10); // M√°ximo 10 mensagens simult√¢neas

   await semaphore.WaitAsync();
   try
   {
       await ProcessMessageAsync(message);
   }
   finally
   {
       semaphore.Release();
   }
   ```

---

## 2. Riscos de Neg√≥cio

### 2.1. Indisponibilidade de Parceiros

**Risco:**
Parceiro cr√≠tico (ex: SAP) fica indispon√≠vel, impedindo integra√ß√µes.

**Mitiga√ß√£o:**
- Modo de conting√™ncia: Armazenar requisi√ß√µes e reprocessar quando parceiro voltar
- SLA claro com parceiros (uptime m√≠nimo: 99.5%)
- Monitoramento proativo de sistemas parceiros

---

### 2.2. Mudan√ßas Regulat√≥rias

**Risco:**
Novas regulamenta√ß√µes (LGPD, BACEN) exigem mudan√ßas r√°pidas.

**Mitiga√ß√£o:**
- Arquitetura flex√≠vel (f√°cil adicionar valida√ß√µes)
- Logs de auditoria completos (compliance desde o in√≠cio)
- Consultor jur√≠dico revisando contratos de integra√ß√£o

---

### 2.3. Crescimento Exponencial

**Risco:**
Ado√ß√£o maior que esperada (10x volume de requisi√ß√µes em 6 meses).

**Mitiga√ß√£o:**
- Arquitetura preparada para escala horizontal
- Load testing regular (simular 10x carga atual)
- Monitoramento de capacidade (CPU, mem√≥ria, IOPS)

---

## 3. Riscos Operacionais

### 3.1. Falta de Documenta√ß√£o

**Risco:**
Equipe nova n√£o consegue manter/evoluir o sistema.

**Mitiga√ß√£o:**
- ‚úÖ Documenta√ß√£o completa em `/docs`
- ‚úÖ Diagramas de arquitetura (Mermaid)
- ‚úÖ Runbooks para incidentes comuns
- ‚úÖ README.md detalhado

---

### 3.2. Falta de Observabilidade

**Risco:**
Incidentes demoram horas para serem diagnosticados.

**Mitiga√ß√£o:**
- ‚úÖ Logs estruturados com Serilog
- ‚úÖ Distributed tracing com OpenTelemetry
- ‚úÖ Dashboards Grafana com m√©tricas cr√≠ticas
- ‚úÖ Alertas em PagerDuty/OpsGenie

---

### 3.3. Deploy Manual

**Risco:**
Erro humano durante deploy causa downtime.

**Mitiga√ß√£o:**
- CI/CD automatizado (GitHub Actions / Azure DevOps)
- Blue-Green Deployment
- Testes automatizados (unit + integration + E2E)
- Rollback autom√°tico se health check falha

---

## 4. Prioriza√ß√£o de Riscos

| Risco | Probabilidade | Impacto | Prioridade | Mitiga√ß√£o |
|-------|---------------|---------|------------|-----------|
| **Lat√™ncia Externa** | Alta | Alto | üî¥ Cr√≠tico | Circuit Breaker + Timeout |
| **Breaking Changes** | M√©dia | Alto | üü† Alto | Versionamento de API |
| **Falhas Intermitentes** | Alta | M√©dio | üü† Alto | Retry + Idempot√™ncia |
| **Fila Cheia** | M√©dia | Alto | üü† Alto | Auto-Scaling + DLQ |
| **Falta de Docs** | Baixa | M√©dio | üü° M√©dio | J√° mitigado (docs criados) |
| **Crescimento 10x** | Baixa | Alto | üü° M√©dio | Load Testing + Escala Horizontal |

---

## 5. Checklist de Produ√ß√£o

### 5.1. Antes do Go-Live

- [ ] Load testing com 10x carga esperada
- [ ] Chaos engineering (simular falhas)
- [ ] Runbooks criados para top 5 incidentes
- [ ] Alertas testados (PagerDuty)
- [ ] Dashboards Grafana configurados
- [ ] SLAs definidos com parceiros
- [ ] Plano de rollback testado
- [ ] Backup/restore testado

---

### 5.2. Primeiros 30 Dias

- [ ] Monitorar m√©tricas diariamente
- [ ] Revisar DLQ semanalmente
- [ ] Post-mortem de incidentes
- [ ] Ajustar alertas (reduzir falsos positivos)
- [ ] Coletar feedback de parceiros
- [ ] Otimizar queries lentas

---

## 6. Conclus√£o

Os principais pontos de aten√ß√£o identificados s√£o:
- ‚úÖ **Mitigados:** Lat√™ncia externa (circuit breaker), falhas intermitentes (retry)
- ‚ö†Ô∏è **Monitorar:** Profundidade da fila, taxa de erro de sistemas externos
- üîÑ **Melhorar:** Auto-scaling, observabilidade avan√ßada, chaos engineering
